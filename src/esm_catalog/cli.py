"""CLI entry point for esm_catalog."""

import click
from loguru import logger

from . import __version__


@click.group()
@click.version_option(version=__version__)
@click.option("-v", "--verbose", is_flag=True, help="Enable verbose logging")
def main(verbose: bool) -> None:
    """ESM Tools STAC catalog generator.

    Generate STAC catalogs from ESM Tools experiment outputs.
    """
    if not verbose:
        logger.remove()
        logger.add(lambda msg: click.echo(msg, nl=False), level="INFO", format="{message}")


@main.command()
@click.argument("experiments_dir", type=click.Path(exists=True, file_okay=False))
@click.option(
    "-o", "--output",
    type=click.Path(),
    default="experiments.json",
    help="Output JSON file path",
)
def extract(experiments_dir: str, output: str) -> None:
    """Extract experiment metadata from ESM Tools experiment directories.

    EXPERIMENTS_DIR is the path containing experiment subdirectories,
    each with a config/*_finished_config.yaml file.
    """
    from .extract import find_experiments, write_experiments_json

    logger.info(f"Scanning {experiments_dir} for experiments...")
    results = find_experiments(experiments_dir)
    logger.info(f"Found {len(results)} experiments")

    write_experiments_json(results, output)
    logger.info(f"Wrote {output}")


@main.command()
@click.argument("experiments_json", type=click.Path(exists=True, dir_okay=False))
@click.option(
    "-o", "--output",
    type=click.Path(),
    default="catalog",
    help="Output catalog directory (or parent for --distributed)",
)
@click.option(
    "--distributed/--unified",
    default=False,
    help="Create catalog/ inside each experiment directory (default: unified)",
)
def build(experiments_json: str, output: str, distributed: bool) -> None:
    """Build STAC catalog from experiments.json.

    EXPERIMENTS_JSON is the metadata file generated by 'extract'.

    With --unified (default): all catalogs in one output directory.
    With --distributed: catalog/ created inside each experiment directory.
    """
    from .build import build_catalog

    mode = "distributed" if distributed else "unified"
    logger.info(f"Building catalog from {experiments_json} ({mode} mode)...")
    build_catalog(experiments_json, output, distributed=distributed)
    logger.info(f"Catalog saved to {output}")


@main.command()
@click.argument("catalog_dir", type=click.Path(exists=True, file_okay=False), default="catalog")
def validate(catalog_dir: str) -> None:
    """Validate a STAC catalog.

    CATALOG_DIR is the catalog directory to validate (default: catalog).
    """
    from .validate import validate_catalog

    errors = validate_catalog(catalog_dir)
    if errors:
        raise SystemExit(1)


@main.command()
@click.argument("catalog_dir", type=click.Path(exists=True, file_okay=False), default="catalog")
@click.option("-p", "--port", type=int, default=9092, help="Port to serve on")
@click.option("--host", default="0.0.0.0", help="Host to bind to")
def serve(catalog_dir: str, port: int, host: str) -> None:
    """Serve STAC catalog via API.

    CATALOG_DIR is the catalog directory to serve (default: catalog).
    """
    from .serve import run_server

    logger.info(f"Starting STAC API on {host}:{port}...")
    run_server(catalog_dir, host=host, port=port)


@main.command()
@click.argument("experiments_json", type=click.Path(exists=True, dir_okay=False))
@click.option(
    "-o", "--output",
    type=click.Path(),
    default="catalog",
    help="Output catalog directory (or parent for --distributed)",
)
@click.option("-c", "--cores", type=int, default=1, help="Number of cores for parallel execution")
@click.option("--use-conda/--no-conda", default=False, help="Use conda environments")
@click.option("--dry-run", "-n", is_flag=True, help="Show what would be done")
@click.option(
    "--distributed/--unified",
    default=True,
    help="Create catalog/ inside each experiment directory (default: distributed)",
)
def snakemake(
    experiments_json: str,
    output: str,
    cores: int,
    use_conda: bool,
    dry_run: bool,
    distributed: bool,
) -> None:
    """Build STAC items using Snakemake workflow.

    EXPERIMENTS_JSON is the metadata file generated by 'extract'.
    Uses Snakemake for parallel processing of NetCDF files.

    With --distributed (default): catalog/ created inside each experiment directory.
    With --unified: all catalogs in one output directory.
    """
    import subprocess
    import sys
    from pathlib import Path
    import importlib.resources

    # Find the bundled Snakefile
    with importlib.resources.as_file(
        importlib.resources.files("esm_catalog.workflow").joinpath("Snakefile")
    ) as snakefile_path:
        cmd = [
            sys.executable, "-m", "snakemake",
            "--snakefile", str(snakefile_path),
            "--cores", str(cores),
            "--config",
            f"experiments_json={experiments_json}",
            f"output_dir={output}",
            f"distributed={'true' if distributed else 'false'}",
        ]

        if use_conda:
            cmd.append("--use-conda")

        if dry_run:
            cmd.append("--dry-run")

        logger.info(f"Running: {' '.join(cmd)}")
        result = subprocess.run(cmd)
        if result.returncode != 0:
            raise SystemExit(result.returncode)

    # Finalize catalog structure (catalog.json, collection.json files)
    if not dry_run:
        from .finalize import finalize_catalog
        logger.info("Finalizing catalog structure...")
        finalize_catalog(experiments_json, output, distributed=distributed)


if __name__ == "__main__":
    main()
